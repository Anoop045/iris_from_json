{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50aed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting striprtf\n",
      "  Downloading striprtf-0.0.22-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: striprtf\n",
      "Successfully installed striprtf-0.0.22\n"
     ]
    }
   ],
   "source": [
    "!pip install striprtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231089df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from striprtf.striprtf import rtf_to_text\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df5ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"algoparams_from_ui.json.rtf\",\"r\")\n",
    "example = file.read()\n",
    "text = rtf_to_text(example)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2690d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4226c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77af379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 read target and type of prediction\n",
    "target_var = data[\"design_state_data\"][\"target\"][\"target\"]\n",
    "prediction_type = data[\"design_state_data\"][\"target\"][\"prediction_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd00dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features imputation details\n",
    "\n",
    "design = data[\"design_state_data\"][\"feature_handling\"]\n",
    "sepal_length_imp_type = design[\"sepal_length\"][\"feature_details\"][\"impute_with\"]\n",
    "sepal_length_imp_val = design[\"sepal_length\"][\"feature_details\"][\"impute_value\"]\n",
    "\n",
    "sepal_width_imp_type = design[\"sepal_width\"][\"feature_details\"][\"impute_with\"]\n",
    "sepal_width_imp_val = design[\"sepal_width\"][\"feature_details\"][\"impute_value\"]\n",
    "\n",
    "petal_length_imp_type = design[\"petal_length\"][\"feature_details\"][\"impute_with\"]\n",
    "petal_length_imp_val =design[\"petal_length\"][\"feature_details\"][\"impute_value\"]\n",
    "\n",
    "petal_width_imp_type = design[\"petal_width\"][\"feature_details\"][\"impute_with\"]\n",
    "petal_width_imp_val = design[\"petal_width\"][\"feature_details\"][\"impute_value\"]\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "if sepal_length_imp_type == 'Average of values':\n",
    "  imputer1 = SimpleImputer(strategy = 'mean')\n",
    "  df['sepal_length']= imputer1.fit_transform(df[['sepal_length']])\n",
    "if sepal_length_imp_type == 'custom':\n",
    "  imputer1 = SimpleImputer(strategy = 'constant',fill_value = sepal_length_imp_val)\n",
    "  df['sepal_length']= imputer1.fit_transform(df[['sepal_length']])\n",
    "if sepal_length_imp_type == 'median':\n",
    "  imputer1 = SimpleImputer(strategy = 'median')\n",
    "  df['sepal_length']= imputer1.fit_transform(df[['sepal_length']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if sepal_width_imp_type == 'Average of values':\n",
    "  imputer2 = SimpleImputer(strategy ='mean')\n",
    "  df['sepal_width']= imputer2.fit_transform(df[['sepal_width']])\n",
    "if sepal_width_imp_type == 'custom':\n",
    "  imputer2 = SimpleImputer(strategy ='constant',fill_value = sepal_width_imp_val)\n",
    "  df['sepal_width']= imputer2.fit_transform(df[['sepal_width']])\n",
    "if sepal_width_imp_type == 'median':\n",
    "  imputer2 = SimpleImputer(strategy ='median')\n",
    "  df['sepal_width']= imputer2.fit_transform(df[['sepal_width']])\n",
    "\n",
    "\n",
    "if petal_length_imp_type == 'Average of values':\n",
    "  imputer3 = SimpleImputer(strategy = 'mean')\n",
    "  df['petal_length']= imputer3.fit_transform(df[['petal_length']])\n",
    "if petal_length_imp_type == 'custom':\n",
    "  imputer3 = SimpleImputer(strategy = 'constant',fill_value = petal_length_imp_val)\n",
    "  df['petal_length']= imputer3.fit_transform(df[['petal_length']])\n",
    "if petal_length_imp_type == 'median':\n",
    "  imputer3 = SimpleImputer(strategy = 'median')\n",
    "  df['petal_length']= imputer3.fit_transform(df[['petal_length']])\n",
    "\n",
    "\n",
    "if petal_width_imp_type == 'Average of values':\n",
    "  imputer4 = SimpleImputer(strategy = 'mean')\n",
    "  df['petal_width']= imputer4.fit_transform(df[['petal_width']])\n",
    "if petal_width_imp_type == 'custom':\n",
    "  imputer4 = SimpleImputer(strategy = 'constant',fill_value = petal_width_imp_val)\n",
    "  df['petal_width']= imputer4.fit_transform(df[['petal_width']])\n",
    "if petal_width_imp_type == 'median':\n",
    "  imputer4 = SimpleImputer(strategy = 'median')\n",
    "  df['petal_width']= imputer4.fit_transform(df[['petal_width']])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "if target_var != \"species\":\n",
    "  df['species'] = LabelEncoder().fit_transform(df['species'])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce2a9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c005f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_var],axis=1)\n",
    "y = df[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22a90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.ma.extras import column_stack\n",
    "#feature reduction details\n",
    "reduction_method = data[\"design_state_data\"][\"feature_reduction\"][\"feature_reduction_method\"]\n",
    "\n",
    "num = int(data[\"design_state_data\"][\"feature_reduction\"][\"num_of_features_to_keep\"])\n",
    "\n",
    "if reduction_method == 'No Reduction':\n",
    "  feature_keep = num\n",
    "  df_reduced = df.iloc[:,0:num+1]\n",
    "\n",
    "if reduction_method == 'Correlation with target':\n",
    "  feature_keep = num\n",
    "  df_reduced = df.iloc[:,0:num+1]\n",
    "\n",
    "if reduction_method == \"Tree-based\":\n",
    "  feature_keep = num\n",
    "  tree_num = int(data[\"design_state_data\"][\"feature_reduction\"][\"num_of_trees\"])\n",
    "  tree_depth = int(data[\"design_state_data\"][\"feature_reduction\"][\"depth_of_trees\"])\n",
    "  if prediction_type == 'Regression':\n",
    "    rf = RandomForestRegressor(n_estimators = tree_num)\n",
    "    rf.fit(X,y)\n",
    "    rf.feature_importances_\n",
    "    df_rf = pd.DataFrame({'features':X.columns,'importances':rf.feature_importances_})\n",
    "    df_rf = df_rf.sort_values(by='importances',ascending = False)\n",
    "    columns=[]\n",
    "    for i in range(num):\n",
    "      columns.append(df_rf.iloc[i,0])\n",
    "    df_reduced = df.loc[:,columns]\n",
    "    df_reduced = df_reduced.join(df[target_var])\n",
    "  if prediction_type==\"Classification\":\n",
    "    rf = RandomForestClassifier(n_estimators = tree_num)\n",
    "    rf.fit(X,y)\n",
    "    rf.feature_importances_\n",
    "    df_rf = pd.DataFrame({'features':X.columns,'importances':rf.feature_importances_})\n",
    "    df_rf = df_rf.sort_values(by='importances',ascending = False)\n",
    "    columns=[]\n",
    "    for i in range(num):\n",
    "      columns.append(df_rf.iloc[i,0])\n",
    "    df_reduced = df.loc[:,columns]\n",
    "    df_reduced = df_reduced.join(df[target_var])\n",
    "\n",
    "\n",
    "if reduction_method == \"Principal Component Analysis\":\n",
    "  feature_keep == num\n",
    "  pca = PCA(n_components = feature_keep)\n",
    "  df_reduced = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c347adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  petal_length  sepal_width  sepal_length  petal_width\n",
       "0        0           1.4          3.5           5.1          0.2\n",
       "1        0           1.4          3.0           4.9          0.2\n",
       "2        0           1.3          3.2           4.7          0.2\n",
       "3        0           1.5          3.1           4.6          0.2\n",
       "4        0           1.4          3.6           5.0          0.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca03a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "X = df_reduced.drop(columns=[target_var],axis=1)\n",
    "y = df_reduced[target_var]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3ffb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.3-py3-none-win_amd64.whl (89.1 MB)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d0f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingClassifier,GradientBoostingRegressor,ExtraTreesRegressor,ExtraTreesClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Ridge,Lasso,ElasticNet,SGDRegressor,SGDClassifier\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor,MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27976615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "folds = data[\"design_state_data\"][\"hyperparameters\"][\"num_of_folds\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2eb30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214139256426638\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    e1 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"min_trees\"]\n",
    "    e2 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"max_trees\"]\n",
    "    d1 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"min_depth\"]\n",
    "    d2 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"max_depth\"]\n",
    "    s1 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"min_samples_per_leaf_min_value\"]\n",
    "    s2 = data[\"design_state_data\"][\"algorithms\"][\"RandomForestRegressor\"][\"min_samples_per_leaf_max_value\"]\n",
    "\n",
    "    params ={'n_estimators':[e1,e2],'max_depth':[d1,d2],\"min_samples_leaf\":[s1,s2]}\n",
    "    g_rfr = GridSearchCV(RandomForestRegressor(),params,cv = folds)\n",
    "    g_rfr.fit(X_train,y_train)\n",
    "    dic_rfr = g_rfr.best_params_\n",
    "    rfr = RandomForestRegressor(max_depth = dic_rfr['max_depth'],min_samples_leaf = dic_rfr['min_samples_leaf'],n_estimators = dic_rfr['n_estimators'])\n",
    "    modelrfr = rfr.fit(X_train,y_train)\n",
    "    y_prfr = rfr.predict(X_test)\n",
    "    s_rfr1 = rfr.score(X_test,y_test)\n",
    "    print(s_rfr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0a65fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083120997272067\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #GBR\n",
    "    e1 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"num_of_BoostingStages\"]\n",
    "    s1 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"min_subsample\"]\n",
    "    s2 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"max_subsample\"]\n",
    "    d1 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"min_depth\"]\n",
    "    d2 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"max_depth\"]\n",
    "    i1 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"min_iter\"]\n",
    "    i2 = data[\"design_state_data\"][\"algorithms\"][\"GBTRegressor\"][\"max_iter\"]\n",
    "    params = {'n_estimators':e1,'max_depth':[d1,d2],'n_iter_no_change':[i1,i2]}\n",
    "    g_gbr = GridSearchCV(GradientBoostingRegressor(),params,cv = folds)\n",
    "    g_gbr.fit(X_train,y_train);\n",
    "    dic_gbr = g_gbr.best_params_\n",
    "    gbr = GradientBoostingRegressor(max_depth = dic_gbr['max_depth'],n_estimators = dic_gbr['n_estimators'],n_iter_no_change = dic_gbr['n_iter_no_change'])\n",
    "    modelgbr = gbr.fit(X_train,y_train)\n",
    "    y_pgbr = gbr.predict(X_test)\n",
    "    s_gbr= gbr.score(X_test,y_test)\n",
    "    print(s_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6358d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.017871849836534226\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #Extratreeregressor\n",
    "    e1 = data[\"design_state_data\"][\"algorithms\"][\"extra_random_trees\"]['num_of_trees']\n",
    "    d1 = data[\"design_state_data\"][\"algorithms\"][\"extra_random_trees\"]['max_depth']\n",
    "    l1 = data[\"design_state_data\"][\"algorithms\"][\"extra_random_trees\"]['min_samples_per_leaf']\n",
    "    params = {'n_estimators':e1,'max_depth':d1,'min_samples_leaf': l1}\n",
    "    g_ext = GridSearchCV(ExtraTreesRegressor(),params,cv = folds)\n",
    "    g_ext.fit(X_train,y_train);\n",
    "    dic_ext = g_ext.best_params_\n",
    "    dic_ext\n",
    "    ext = ExtraTreesRegressor(max_depth = dic_ext['max_depth'],n_estimators = dic_ext['n_estimators'],min_samples_leaf=dic_ext['min_samples_leaf'])\n",
    "    modelext = ext.fit(X_train,y_train)\n",
    "    y_pext = ext.predict(X_test)\n",
    "    s_ext = ext.score(X_test,y_test)\n",
    "    print(s_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07132b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9323483696029023\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #Linearregression\n",
    "    lin=LinearRegression()\n",
    "    modellin = lin.fit(X_train,y_train)\n",
    "    y_plin = lin.predict(X_test)\n",
    "    s_lin = lin.score(X_test,y_test)\n",
    "    print(s_lin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6296453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316430518164385\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #ridge\n",
    "    i1=data[\"design_state_data\"][\"algorithms\"][\"RidgeRegression\"]['min_iter']\n",
    "    i2=data[\"design_state_data\"][\"algorithms\"][\"RidgeRegression\"]['max_iter']\n",
    "    a1 =data[\"design_state_data\"][\"algorithms\"][\"RidgeRegression\"]['min_regparam']\n",
    "    a2 =data[\"design_state_data\"][\"algorithms\"][\"RidgeRegression\"]['max_regparam']\n",
    "    params= {'max_iter':[i1,i2],'alpha':[a1,a2]}\n",
    "    g_rid = GridSearchCV(Ridge(),params,cv = folds)\n",
    "    g_rid.fit(X_train,y_train);\n",
    "    dic_rid = g_rid.best_params_\n",
    "    dic_rid\n",
    "    rid = Ridge(max_iter = dic_rid['max_iter'],alpha = dic_rid['alpha'])\n",
    "    modelrid = rid.fit(X_train,y_train)\n",
    "    y_prid = rid.predict(X_test)\n",
    "    s_rid = rid.score(X_test,y_test)\n",
    "    print(s_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "420b7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7871637749252313\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #lasso\n",
    "    i1=data[\"design_state_data\"][\"algorithms\"][\"LassoRegression\"]['min_iter']\n",
    "    i2=data[\"design_state_data\"][\"algorithms\"][\"LassoRegression\"]['max_iter']\n",
    "    a1 =data[\"design_state_data\"][\"algorithms\"][\"LassoRegression\"]['min_regparam']\n",
    "    a2 =data[\"design_state_data\"][\"algorithms\"][\"LassoRegression\"]['max_regparam']\n",
    "    params= {'max_iter':[i1,i2],'alpha':[a1,a2]}\n",
    "    g_las = GridSearchCV(Lasso(),params,cv = folds)\n",
    "    g_las.fit(X_train,y_train);\n",
    "    dic_las = g_las.best_params_\n",
    "    dic_las\n",
    "    las = Lasso(max_iter = dic_las['max_iter'],alpha = dic_las['alpha'])\n",
    "    modellas = las.fit(X_train,y_train)\n",
    "    y_plas = las.predict(X_test)\n",
    "    s_las = las.score(X_test,y_test)\n",
    "    print(s_las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ceb28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536585607724704\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #elasticnet\n",
    "    i1=data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['min_iter']\n",
    "    i2=data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['max_iter']\n",
    "    a1 =data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['min_regparam']\n",
    "    a2 =data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['max_regparam']\n",
    "    e1 =data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['min_elasticnet']\n",
    "    e2 =data[\"design_state_data\"][\"algorithms\"][\"ElasticNetRegression\"]['max_elasticnet']\n",
    "    params= {'max_iter':[i1,i2],'alpha':[a1,a2],'l1_ratio':[e1,e2]}\n",
    "    g_els = GridSearchCV(ElasticNet(),params,cv = folds)\n",
    "    g_els.fit(X_train,y_train);\n",
    "    dic_els = g_els.best_params_\n",
    "    dic_els\n",
    "    els = ElasticNet(max_iter = dic_els['max_iter'],alpha = dic_els['alpha'],l1_ratio = dic_els['l1_ratio'])\n",
    "    modelels = els.fit(X_train,y_train)\n",
    "    y_pels = els.predict(X_test)\n",
    "    s_els = els.score(X_test,y_test)\n",
    "    print(s_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd01e99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.029156691223380937\n"
     ]
    }
   ],
   "source": [
    "if prediction_type =='Regression':\n",
    "    #SGD\n",
    "    t1=data[\"design_state_data\"][\"algorithms\"][\"SGD\"][\"tolerance\"]\n",
    "    if data[\"design_state_data\"][\"algorithms\"][\"SGD\"][\"use_elastic_net_regularization\"]==True:\n",
    "      e1 = 'elasticnet'\n",
    "    else:\n",
    "      e1 = 'l2'\n",
    "    a1 = data[\"design_state_data\"][\"algorithms\"][\"SGD\"][\"alpha_value\"]\n",
    "    params = {'tol':[t1],'penalty':[e1],'alpha':a1}\n",
    "    g_sgd = GridSearchCV(SGDRegressor(),params,cv = folds)\n",
    "    g_sgd.fit(X_train,y_train);\n",
    "    dic_sgd = g_sgd.best_params_\n",
    "    dic_sgd\n",
    "    sgd = SGDRegressor(tol=dic_sgd['tol'],penalty=dic_sgd['penalty'],alpha=dic_sgd['alpha'])\n",
    "    modelsgd = sgd.fit(X_train,y_train)\n",
    "    y_psgd = sgd.predict(X_test)\n",
    "    s_sgd = sgd.score(X_test,y_test)\n",
    "    print(s_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46c80fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m modelxgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     12\u001b[0m y_pxgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mpredict(X_test);\n\u001b[1;32m---> 13\u001b[0m s_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(s_xgb)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:706\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m    705\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:789\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr2_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    -3.0\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:96\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     95\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     99\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "if prediction_type==\"Regression\":\n",
    "    #XGbRegressor\n",
    "    l1=data[\"design_state_data\"][\"algorithms\"][\"xg_boost\"][\"learningRate\"]\n",
    "    d1=data[\"design_state_data\"][\"algorithms\"][\"xg_boost\"][\"max_depth_of_tree\"]\n",
    "    params={'max_depth':d1,'learning_rate':l1}\n",
    "    g_xgb = GridSearchCV(XGBRegressor(),params,cv = folds)\n",
    "    g_xgb.fit(X_train,y_train);\n",
    "    dic_xgb = g_xgb.best_params_\n",
    "    dic_xgb\n",
    "    xgb = XGBRegressor(max_depth=dic_xgb['max_depth'],learning_rate=dic_xgb['learning_rate'])\n",
    "    modelxgb = xgb.fit(X_train,y_train)\n",
    "    y_pxgb = xgb.predict(X_test);\n",
    "    s_xgb = xgb.score(X_test,y_test)\n",
    "    print(s_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119a64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0d7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038694958386728\n"
     ]
    }
   ],
   "source": [
    "if prediction_type==\"Regression\":\n",
    "    #DTR\n",
    "    d1 = data[\"design_state_data\"][\"algorithms\"][\"DecisionTreeRegressor\"][\"min_depth\"]\n",
    "    d2 = data[\"design_state_data\"][\"algorithms\"][\"DecisionTreeRegressor\"][\"max_depth\"]\n",
    "    s1 = data[\"design_state_data\"][\"algorithms\"][\"DecisionTreeRegressor\"][\"min_samples_per_leaf\"]\n",
    "    params = {'max_depth':[d1,d2],'min_samples_leaf':s1}\n",
    "    g_dtr = GridSearchCV(DecisionTreeRegressor(),params,cv = folds)\n",
    "    g_dtr.fit(X_train,y_train);\n",
    "    dic_dtr = g_dtr.best_params_\n",
    "    dic_dtr\n",
    "    dtr = DecisionTreeRegressor(max_depth=dic_dtr['max_depth'],min_samples_leaf= dic_dtr['min_samples_leaf'])\n",
    "    modeldtr = dtr.fit(X_train,y_train)\n",
    "    y_pdtr = dtr.predict(X_test)\n",
    "    s_dtr = dtr.score(X_test,y_test)\n",
    "    print(s_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a63c853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05997586769820429\n"
     ]
    }
   ],
   "source": [
    "if prediction_type==\"Regression\":\n",
    "    #SVR\n",
    "    c1 = data[\"design_state_data\"][\"algorithms\"][\"SVM\"]['c_value']\n",
    "    t1 = data[\"design_state_data\"][\"algorithms\"][\"SVM\"]['tolerance']\n",
    "    i1 = data[\"design_state_data\"][\"algorithms\"][\"SVM\"]['max_iterations']\n",
    "    params = {\"C\":c1,'tol':[t1],'max_iter':[i1]}\n",
    "    g_svr = GridSearchCV(SVR(),params,cv = folds)\n",
    "    g_svr.fit(X_train,y_train);\n",
    "    dic_svr = g_svr.best_params_\n",
    "    dic_svr\n",
    "    svr =SVR(C=dic_svr[\"C\"],tol = dic_svr['tol'],max_iter = dic_svr['max_iter'])\n",
    "    modelsvr = svr.fit(X_train,y_train)\n",
    "    y_psvr = svr.predict(X_test)\n",
    "    s_svr = svr.score(X_test,y_test)\n",
    "    print(s_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b854f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9356786145219675\n"
     ]
    }
   ],
   "source": [
    "if prediction_type==\"Regression\":\n",
    "    #knn\n",
    "    alg_name= data[\"design_state_data\"][\"algorithms\"][\"KNN\"][\"neighbour_finding_algorithm\"]\n",
    "    if alg_name==\"Automatic\":\n",
    "      Algorithm = \"auto\"\n",
    "    knn = KNeighborsRegressor(algorithm = Algorithm)\n",
    "    modelknn = knn.fit(X_train,y_train)\n",
    "    y_pknn = knn.predict(X_test)\n",
    "    s_knn= knn.score(X_test,y_test)\n",
    "    print(s_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "161c72fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8610019093348302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if prediction_type==\"Regression\":\n",
    "    #neural\n",
    "    hl = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['hidden_layer_sizes']\n",
    "    s1 = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['solver']\n",
    "    if s1=='ADAM':\n",
    "      sol = 'adam'\n",
    "    b1 = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['beta_1']\n",
    "    b2 = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['beta_2']\n",
    "    ep = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['epsilon']\n",
    "    es = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['early_stopping']\n",
    "    m1 = data[\"design_state_data\"][\"algorithms\"][\"neural_network\"]['momentum']\n",
    "    params = {'hidden_layer_sizes':hl,\"solver\":[sol]}\n",
    "    g_mlpr = GridSearchCV(MLPRegressor(),params,cv = folds)\n",
    "    g_mlpr.fit(X_train,y_train)\n",
    "    dic_mlpr = g_mlpr.best_params_\n",
    "    dic_mlpr\n",
    "    mlpr = MLPRegressor(solver=dic_mlpr['solver'],beta_1 = b1,beta_2 = b2 ,early_stopping= es, momentum = m1,hidden_layer_sizes=dic_mlpr['hidden_layer_sizes'])\n",
    "    modelmlpr = mlpr.fit(X_train,y_train)\n",
    "    y_pmlpr = mlpr.predict(X_test)\n",
    "    s_mlpr= mlpr.score(X_test,y_test)\n",
    "    print(s_mlpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bbda6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if prediction_type==\"Classification\":\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
